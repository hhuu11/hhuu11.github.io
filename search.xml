<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title></title>
      <link href="/2024/07/18/INFO212-group18-code/"/>
      <url>/2024/07/18/INFO212-group18-code/</url>
      
        <content type="html"><![CDATA[<h1 id="Data-Preparation"><a href="#Data-Preparation" class="headerlink" title="Data Preparation"></a>Data Preparation</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;mxmh_survey_results.csv&#x27;</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>Timestamp</th>      <th>Age</th>      <th>Primary streaming service</th>      <th>Hours per day</th>      <th>While working</th>      <th>Instrumentalist</th>      <th>Composer</th>      <th>Fav genre</th>      <th>Exploratory</th>      <th>Foreign languages</th>      <th>...</th>      <th>Frequency [R&amp;B]</th>      <th>Frequency [Rap]</th>      <th>Frequency [Rock]</th>      <th>Frequency [Video game music]</th>      <th>Anxiety</th>      <th>Depression</th>      <th>Insomnia</th>      <th>OCD</th>      <th>Music effects</th>      <th>Permissions</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>8/27/2022 19:29:02</td>      <td>18.0</td>      <td>Spotify</td>      <td>3.0</td>      <td>Yes</td>      <td>Yes</td>      <td>Yes</td>      <td>Latin</td>      <td>Yes</td>      <td>Yes</td>      <td>...</td>      <td>Sometimes</td>      <td>Very frequently</td>      <td>Never</td>      <td>Sometimes</td>      <td>3.0</td>      <td>0.0</td>      <td>1.0</td>      <td>0.0</td>      <td>NaN</td>      <td>I understand.</td>    </tr>    <tr>      <th>1</th>      <td>8/27/2022 19:57:31</td>      <td>63.0</td>      <td>Pandora</td>      <td>1.5</td>      <td>Yes</td>      <td>No</td>      <td>No</td>      <td>Rock</td>      <td>Yes</td>      <td>No</td>      <td>...</td>      <td>Sometimes</td>      <td>Rarely</td>      <td>Very frequently</td>      <td>Rarely</td>      <td>7.0</td>      <td>2.0</td>      <td>2.0</td>      <td>1.0</td>      <td>NaN</td>      <td>I understand.</td>    </tr>    <tr>      <th>2</th>      <td>8/27/2022 21:28:18</td>      <td>18.0</td>      <td>Spotify</td>      <td>4.0</td>      <td>No</td>      <td>No</td>      <td>No</td>      <td>Video game music</td>      <td>No</td>      <td>Yes</td>      <td>...</td>      <td>Never</td>      <td>Rarely</td>      <td>Rarely</td>      <td>Very frequently</td>      <td>7.0</td>      <td>7.0</td>      <td>10.0</td>      <td>2.0</td>      <td>No effect</td>      <td>I understand.</td>    </tr>    <tr>      <th>3</th>      <td>8/27/2022 21:40:40</td>      <td>61.0</td>      <td>YouTube Music</td>      <td>2.5</td>      <td>Yes</td>      <td>No</td>      <td>Yes</td>      <td>Jazz</td>      <td>Yes</td>      <td>Yes</td>      <td>...</td>      <td>Sometimes</td>      <td>Never</td>      <td>Never</td>      <td>Never</td>      <td>9.0</td>      <td>7.0</td>      <td>3.0</td>      <td>3.0</td>      <td>Improve</td>      <td>I understand.</td>    </tr>    <tr>      <th>4</th>      <td>8/27/2022 21:54:47</td>      <td>18.0</td>      <td>Spotify</td>      <td>4.0</td>      <td>Yes</td>      <td>No</td>      <td>No</td>      <td>R&amp;B</td>      <td>Yes</td>      <td>No</td>      <td>...</td>      <td>Very frequently</td>      <td>Very frequently</td>      <td>Never</td>      <td>Rarely</td>      <td>7.0</td>      <td>2.0</td>      <td>5.0</td>      <td>9.0</td>      <td>Improve</td>      <td>I understand.</td>    </tr>  </tbody></table><p>5 rows × 33 columns</p></div><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.info()</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;RangeIndex: 736 entries, 0 to 735Data columns (total 33 columns): #   Column                        Non-Null Count  Dtype  ---  ------                        --------------  -----   0   Timestamp                     736 non-null    object  1   Age                           735 non-null    float64 2   Primary streaming service     735 non-null    object  3   Hours per day                 736 non-null    float64 4   While working                 733 non-null    object  5   Instrumentalist               732 non-null    object  6   Composer                      735 non-null    object  7   Fav genre                     736 non-null    object  8   Exploratory                   736 non-null    object  9   Foreign languages             732 non-null    object  10  BPM                           629 non-null    float64 11  Frequency [Classical]         736 non-null    object  12  Frequency [Country]           736 non-null    object  13  Frequency [EDM]               736 non-null    object  14  Frequency [Folk]              736 non-null    object  15  Frequency [Gospel]            736 non-null    object  16  Frequency [Hip hop]           736 non-null    object  17  Frequency [Jazz]              736 non-null    object  18  Frequency [K pop]             736 non-null    object  19  Frequency [Latin]             736 non-null    object  20  Frequency [Lofi]              736 non-null    object  21  Frequency [Metal]             736 non-null    object  22  Frequency [Pop]               736 non-null    object  23  Frequency [R&amp;B]               736 non-null    object  24  Frequency [Rap]               736 non-null    object  25  Frequency [Rock]              736 non-null    object  26  Frequency [Video game music]  736 non-null    object  27  Anxiety                       736 non-null    float64 28  Depression                    736 non-null    float64 29  Insomnia                      736 non-null    float64 30  OCD                           736 non-null    float64 31  Music effects                 728 non-null    object  32  Permissions                   736 non-null    object dtypes: float64(7), object(26)memory usage: 189.9+ KB</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">missing_percentages = df.isnull().mean() * <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Draw a horizontal bar chart</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">missing_percentages.plot(kind=<span class="string">&#x27;barh&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Percentage of Missing Data by Column&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Percentage of Missing Data&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Columns&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/INFO212-group18-code_files/INFO212-group18-code_3_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Delete all rows with missing values except for BPM columns</span></span><br><span class="line">df_cleaned = df.dropna(subset=[col <span class="keyword">for</span> col <span class="keyword">in</span> df.columns <span class="keyword">if</span> col != <span class="string">&#x27;BPM&#x27;</span>])</span><br><span class="line">df_cleaned.info()</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;Index: 718 entries, 2 to 735Data columns (total 33 columns): #   Column                        Non-Null Count  Dtype  ---  ------                        --------------  -----   0   Timestamp                     718 non-null    object  1   Age                           718 non-null    float64 2   Primary streaming service     718 non-null    object  3   Hours per day                 718 non-null    float64 4   While working                 718 non-null    object  5   Instrumentalist               718 non-null    object  6   Composer                      718 non-null    object  7   Fav genre                     718 non-null    object  8   Exploratory                   718 non-null    object  9   Foreign languages             718 non-null    object  10  BPM                           616 non-null    float64 11  Frequency [Classical]         718 non-null    object  12  Frequency [Country]           718 non-null    object  13  Frequency [EDM]               718 non-null    object  14  Frequency [Folk]              718 non-null    object  15  Frequency [Gospel]            718 non-null    object  16  Frequency [Hip hop]           718 non-null    object  17  Frequency [Jazz]              718 non-null    object  18  Frequency [K pop]             718 non-null    object  19  Frequency [Latin]             718 non-null    object  20  Frequency [Lofi]              718 non-null    object  21  Frequency [Metal]             718 non-null    object  22  Frequency [Pop]               718 non-null    object  23  Frequency [R&amp;B]               718 non-null    object  24  Frequency [Rap]               718 non-null    object  25  Frequency [Rock]              718 non-null    object  26  Frequency [Video game music]  718 non-null    object  27  Anxiety                       718 non-null    float64 28  Depression                    718 non-null    float64 29  Insomnia                      718 non-null    float64 30  OCD                           718 non-null    float64 31  Music effects                 718 non-null    object  32  Permissions                   718 non-null    object dtypes: float64(7), object(26)memory usage: 190.7+ KB</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Create a new data box to avoid modifying the original df_clean</span></span><br><span class="line">df_temp = df_cleaned.copy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a new column to indicate whether it is influenced by music</span></span><br><span class="line">df_temp.loc[:, <span class="string">&#x27;Music Influenced&#x27;</span>] = (df_temp[<span class="string">&#x27;Instrumentalist&#x27;</span>] == <span class="string">&#x27;Yes&#x27;</span>) | (df_temp[<span class="string">&#x27;Composer&#x27;</span>] == <span class="string">&#x27;Yes&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Applying a frequency mapping dictionary to frequency columns</span></span><br><span class="line">frequency_mapping = &#123;</span><br><span class="line">    <span class="string">&#x27;Never&#x27;</span>: <span class="number">0</span>,</span><br><span class="line">    <span class="string">&#x27;Rarely&#x27;</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="string">&#x27;Sometimes&#x27;</span>: <span class="number">2</span>,</span><br><span class="line">    <span class="string">&#x27;Very frequently&#x27;</span>: <span class="number">3</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">frequency_columns = [<span class="string">&#x27;Frequency [Classical]&#x27;</span>, <span class="string">&#x27;Frequency [Country]&#x27;</span>, <span class="string">&#x27;Frequency [EDM]&#x27;</span>, </span><br><span class="line">                     <span class="string">&#x27;Frequency [Folk]&#x27;</span>, <span class="string">&#x27;Frequency [Gospel]&#x27;</span>, <span class="string">&#x27;Frequency [Hip hop]&#x27;</span>, </span><br><span class="line">                     <span class="string">&#x27;Frequency [Jazz]&#x27;</span>, <span class="string">&#x27;Frequency [K pop]&#x27;</span>, <span class="string">&#x27;Frequency [Latin]&#x27;</span>, </span><br><span class="line">                     <span class="string">&#x27;Frequency [Lofi]&#x27;</span>, <span class="string">&#x27;Frequency [Metal]&#x27;</span>, <span class="string">&#x27;Frequency [Pop]&#x27;</span>, </span><br><span class="line">                     <span class="string">&#x27;Frequency [R&amp;B]&#x27;</span>, <span class="string">&#x27;Frequency [Rap]&#x27;</span>, <span class="string">&#x27;Frequency [Rock]&#x27;</span>, </span><br><span class="line">                     <span class="string">&#x27;Frequency [Video game music]&#x27;</span>]</span><br><span class="line"></span><br><span class="line">df_temp[frequency_columns] = df_temp[frequency_columns].apply(<span class="keyword">lambda</span> x: x.<span class="built_in">map</span>(frequency_mapping))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line">psych_columns = [<span class="string">&#x27;Anxiety&#x27;</span>, <span class="string">&#x27;Depression&#x27;</span>, <span class="string">&#x27;Insomnia&#x27;</span>, <span class="string">&#x27;OCD&#x27;</span>]</span><br><span class="line"><span class="comment"># Standardize each indicator</span></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">df_temp.loc[:, psych_columns] = scaler.fit_transform(df_temp[psych_columns])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Calculate comprehensive mental health score (sum of standardized scores)</span></span><br><span class="line">df_temp.loc[:, <span class="string">&#x27;Mental_Health_Score&#x27;</span>] = df_temp[psych_columns].<span class="built_in">sum</span>(axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># View the first few rows of data</span></span><br><span class="line">df_temp[[<span class="string">&#x27;Anxiety&#x27;</span>, <span class="string">&#x27;Depression&#x27;</span>, <span class="string">&#x27;Insomnia&#x27;</span>, <span class="string">&#x27;OCD&#x27;</span>, <span class="string">&#x27;Mental_Health_Score&#x27;</span>]].head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>Anxiety</th>      <th>Depression</th>      <th>Insomnia</th>      <th>OCD</th>      <th>Mental_Health_Score</th>    </tr>  </thead>  <tbody>    <tr>      <th>2</th>      <td>0.417688</td>      <td>0.726847</td>      <td>2.038140</td>      <td>-0.223437</td>      <td>2.959238</td>    </tr>    <tr>      <th>3</th>      <td>1.136442</td>      <td>0.726847</td>      <td>-0.232937</td>      <td>0.128378</td>      <td>1.758731</td>    </tr>    <tr>      <th>4</th>      <td>0.417688</td>      <td>-0.929903</td>      <td>0.415942</td>      <td>2.239270</td>      <td>2.142998</td>    </tr>    <tr>      <th>5</th>      <td>0.777065</td>      <td>1.058197</td>      <td>1.064821</td>      <td>1.535639</td>      <td>4.435723</td>    </tr>    <tr>      <th>6</th>      <td>-0.660443</td>      <td>1.058197</td>      <td>0.740382</td>      <td>-0.927068</td>      <td>0.211069</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Divide into two tables based on the values in the Music effects column</span></span><br><span class="line">df_no_effect = df_temp[df_temp[<span class="string">&#x27;Music effects&#x27;</span>] == <span class="string">&#x27;No effect&#x27;</span>]</span><br><span class="line">df_improve = df_temp[df_temp[<span class="string">&#x27;Music effects&#x27;</span>] == <span class="string">&#x27;Improve&#x27;</span>]</span><br><span class="line"></span><br><span class="line">df_no_effect.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>Timestamp</th>      <th>Age</th>      <th>Primary streaming service</th>      <th>Hours per day</th>      <th>While working</th>      <th>Instrumentalist</th>      <th>Composer</th>      <th>Fav genre</th>      <th>Exploratory</th>      <th>Foreign languages</th>      <th>...</th>      <th>Frequency [Rock]</th>      <th>Frequency [Video game music]</th>      <th>Anxiety</th>      <th>Depression</th>      <th>Insomnia</th>      <th>OCD</th>      <th>Music effects</th>      <th>Permissions</th>      <th>Music Influenced</th>      <th>Mental_Health_Score</th>    </tr>  </thead>  <tbody>    <tr>      <th>2</th>      <td>8/27/2022 21:28:18</td>      <td>18.0</td>      <td>Spotify</td>      <td>4.0</td>      <td>No</td>      <td>No</td>      <td>No</td>      <td>Video game music</td>      <td>No</td>      <td>Yes</td>      <td>...</td>      <td>1</td>      <td>3</td>      <td>0.417688</td>      <td>0.726847</td>      <td>2.038140</td>      <td>-0.223437</td>      <td>No effect</td>      <td>I understand.</td>      <td>False</td>      <td>2.959238</td>    </tr>    <tr>      <th>10</th>      <td>8/27/2022 22:51:15</td>      <td>18.0</td>      <td>Spotify</td>      <td>3.0</td>      <td>Yes</td>      <td>Yes</td>      <td>No</td>      <td>Country</td>      <td>Yes</td>      <td>No</td>      <td>...</td>      <td>1</td>      <td>0</td>      <td>0.417688</td>      <td>0.726847</td>      <td>0.091503</td>      <td>1.535639</td>      <td>No effect</td>      <td>I understand.</td>      <td>True</td>      <td>2.771678</td>    </tr>    <tr>      <th>23</th>      <td>8/28/2022 3:19:08</td>      <td>18.0</td>      <td>Spotify</td>      <td>2.0</td>      <td>Yes</td>      <td>No</td>      <td>No</td>      <td>Pop</td>      <td>No</td>      <td>Yes</td>      <td>...</td>      <td>0</td>      <td>1</td>      <td>-1.019820</td>      <td>-0.598553</td>      <td>1.389261</td>      <td>1.183824</td>      <td>No effect</td>      <td>I understand.</td>      <td>False</td>      <td>0.954712</td>    </tr>    <tr>      <th>31</th>      <td>8/28/2022 10:38:05</td>      <td>19.0</td>      <td>Spotify</td>      <td>2.0</td>      <td>Yes</td>      <td>No</td>      <td>No</td>      <td>Classical</td>      <td>No</td>      <td>No</td>      <td>...</td>      <td>0</td>      <td>3</td>      <td>-0.660443</td>      <td>-0.267203</td>      <td>0.091503</td>      <td>0.128378</td>      <td>No effect</td>      <td>I understand.</td>      <td>False</td>      <td>-0.707765</td>    </tr>    <tr>      <th>34</th>      <td>8/28/2022 11:08:51</td>      <td>16.0</td>      <td>Spotify</td>      <td>1.0</td>      <td>Yes</td>      <td>No</td>      <td>No</td>      <td>Classical</td>      <td>No</td>      <td>No</td>      <td>...</td>      <td>0</td>      <td>1</td>      <td>-2.097951</td>      <td>-1.592603</td>      <td>-1.206255</td>      <td>-0.927068</td>      <td>No effect</td>      <td>I understand.</td>      <td>False</td>      <td>-5.823877</td>    </tr>  </tbody></table><p>5 rows × 35 columns</p></div><h1 id="EDA-Analysis"><a href="#EDA-Analysis" class="headerlink" title="EDA Analysis"></a>EDA Analysis</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Data cleaning</span></span><br><span class="line">valid_age_range = (<span class="number">0</span>, <span class="number">100</span>)  <span class="comment"># Effective range of age</span></span><br><span class="line">valid_frequencies = [<span class="string">&#x27;Rarely&#x27;</span>, <span class="string">&#x27;Sometimes&#x27;</span>, <span class="string">&#x27;Never&#x27;</span>, <span class="string">&#x27;Very frequently&#x27;</span>]  <span class="comment"># Effective options for frequency</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Clean frequency column</span></span><br><span class="line">frequency_columns = [col <span class="keyword">for</span> col <span class="keyword">in</span> df_cleaned.columns <span class="keyword">if</span> col.startswith(<span class="string">&#x27;Frequency [&#x27;</span>)]</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> frequency_columns:</span><br><span class="line">    df_cleaned = df_cleaned[df_cleaned[col].isin(valid_frequencies)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Frequency distribution of statistical age</span></span><br><span class="line">age_counts = df_cleaned[<span class="string">&#x27;Age&#x27;</span>].value_counts().sort_index()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Draw a scatter plot</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">plt.plot(age_counts.index, age_counts.values, color=<span class="string">&#x27;b&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Age Distribution&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Age&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Frequency&#x27;</span>)</span><br><span class="line">plt.grid(<span class="literal">True</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/INFO212-group18-code_files/INFO212-group18-code_9_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Define age bins and labels</span></span><br><span class="line">bins = [<span class="number">10</span>, <span class="number">18</span>, <span class="number">30</span>, <span class="number">50</span>, <span class="number">90</span>]</span><br><span class="line">labels = [<span class="string">&#x27;10-18&#x27;</span>, <span class="string">&#x27;19-30&#x27;</span>, <span class="string">&#x27;31-50&#x27;</span>, <span class="string">&#x27;51-90&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Assuming df_temp is your DataFrame with &#x27;Age&#x27;, &#x27;Fav genre&#x27;, and &#x27;Mental_Health_Score&#x27; columns</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create &#x27;Age Group&#x27; column</span></span><br><span class="line">df_temp[<span class="string">&#x27;Age Group&#x27;</span>] = pd.cut(df_temp[<span class="string">&#x27;Age&#x27;</span>], bins=bins, labels=labels, right=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a cross table to count the number of different &#x27;Fav genre&#x27; in each &#x27;Age Group&#x27;</span></span><br><span class="line">genre_by_age = pd.crosstab(df_temp[<span class="string">&#x27;Age Group&#x27;</span>], df_temp[<span class="string">&#x27;Fav genre&#x27;</span>], normalize=<span class="string">&#x27;index&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Calculate mean &#x27;Mental_Health_Score&#x27; by &#x27;Age Group&#x27;</span></span><br><span class="line">mental_health_score_by_age = df_temp.groupby(<span class="string">&#x27;Age Group&#x27;</span>)[<span class="string">&#x27;Mental_Health_Score&#x27;</span>].mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plotting side-by-side</span></span><br><span class="line">fig, (ax1, ax2) = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">18</span>, <span class="number">8</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Stacked bar chart for &#x27;Fav genre&#x27; distribution by &#x27;Age Group&#x27;</span></span><br><span class="line">genre_by_age.plot(kind=<span class="string">&#x27;bar&#x27;</span>, stacked=<span class="literal">True</span>, colormap=<span class="string">&#x27;tab20&#x27;</span>, ax=ax1)</span><br><span class="line">ax1.set_title(<span class="string">&#x27;Favorite Genre Distribution by Age Group&#x27;</span>)</span><br><span class="line">ax1.set_xlabel(<span class="string">&#x27;Age Group&#x27;</span>)</span><br><span class="line">ax1.set_ylabel(<span class="string">&#x27;Proportion&#x27;</span>)</span><br><span class="line">ax1.set_xticklabels(labels, rotation=<span class="number">0</span>)</span><br><span class="line">ax1.legend(title=<span class="string">&#x27;Fav genre&#x27;</span>, bbox_to_anchor=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Bar chart for mean &#x27;Mental_Health_Score&#x27; by &#x27;Age Group&#x27;</span></span><br><span class="line">ax2.bar(mental_health_score_by_age.index, mental_health_score_by_age.values, color=<span class="string">&#x27;b&#x27;</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line">ax2.set_title(<span class="string">&#x27;Mean Mental Health Score by Age Group&#x27;</span>)</span><br><span class="line">ax2.set_xlabel(<span class="string">&#x27;Age Group&#x27;</span>)</span><br><span class="line">ax2.set_ylabel(<span class="string">&#x27;Mean Mental Health Score&#x27;</span>)</span><br><span class="line">ax2.set_xticks(<span class="built_in">range</span>(<span class="built_in">len</span>(labels)))</span><br><span class="line">ax2.set_xticklabels(labels, rotation=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/INFO212-group18-code_files/INFO212-group18-code_10_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line">sns.countplot(data=df_temp, x=<span class="string">&#x27;Fav genre&#x27;</span>, order=df_temp[<span class="string">&#x27;Fav genre&#x27;</span>].value_counts().index, palette=<span class="string">&#x27;viridis&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Popularity of Different Music Genres&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Favorite Music Genre&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Count&#x27;</span>)</span><br><span class="line">plt.xticks(rotation=<span class="number">45</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/INFO212-group18-code_files/INFO212-group18-code_11_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Divide into two groups according to the music affected markers</span></span><br><span class="line">music_influenced_group = df_temp[df_temp[<span class="string">&#x27;Music Influenced&#x27;</span>] == <span class="literal">True</span>]</span><br><span class="line">non_music_influenced_group = df_temp[df_temp[<span class="string">&#x27;Music Influenced&#x27;</span>] == <span class="literal">False</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Statistics on the distribution of different music genres</span></span><br><span class="line">music_influenced_counts = music_influenced_group[<span class="string">&#x27;Fav genre&#x27;</span>].value_counts(normalize=<span class="literal">True</span>)</span><br><span class="line">non_music_influenced_counts = non_music_influenced_group[<span class="string">&#x27;Fav genre&#x27;</span>].value_counts(normalize=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Merge two sets of data and calculate the proportion</span></span><br><span class="line">merged_counts = pd.concat([music_influenced_counts, non_music_influenced_counts], axis=<span class="number">1</span>)</span><br><span class="line">merged_counts.columns = [<span class="string">&#x27;Music Influenced&#x27;</span>, <span class="string">&#x27;Non Music Influenced&#x27;</span>]</span><br><span class="line">merged_counts = merged_counts.fillna(<span class="number">0</span>)  <span class="comment"># Fill in missing values as 0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Draw a bar chart after sorting</span></span><br><span class="line">merged_counts.sort_values(by=<span class="string">&#x27;Music Influenced&#x27;</span>, ascending=<span class="literal">False</span>).plot(kind=<span class="string">&#x27;bar&#x27;</span>, figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line">plt.title(<span class="string">&#x27;Favorite Music Genres Comparison&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Music Genres&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Proportion&#x27;</span>)</span><br><span class="line">plt.xticks(rotation=<span class="number">45</span>, ha=<span class="string">&#x27;right&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;Music Influenced&#x27;</span>, <span class="string">&#x27;Non Music Influenced&#x27;</span>])</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/INFO212-group18-code_files/INFO212-group18-code_12_0.png" alt="png"></p><h1 id="Statistical-Analysis"><a href="#Statistical-Analysis" class="headerlink" title="Statistical Analysis"></a>Statistical Analysis</h1><ol><li><p>Is there a significant correlation between music taste and self-reported mental health conditions such as anxiety, depression, insomnia, and obsessive compulsive disorder?</p></li><li><p>Which genres of music are associated with better mental health?</p></li></ol><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">columns_of_interest = [</span><br><span class="line">    <span class="string">&#x27;Fav genre&#x27;</span>, <span class="string">&#x27;Anxiety&#x27;</span>, <span class="string">&#x27;Depression&#x27;</span>, <span class="string">&#x27;Insomnia&#x27;</span>, <span class="string">&#x27;OCD&#x27;</span>, <span class="string">&#x27;Mental_Health_Score&#x27;</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">df_interest = df_no_effect[columns_of_interest]</span><br><span class="line">df_interest_encoded = pd.get_dummies(df_interest, columns=[<span class="string">&#x27;Fav genre&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Calculate correlation coefficient</span></span><br><span class="line">correlation_matrix = df_interest_encoded.corr()</span><br><span class="line"></span><br><span class="line">psych_columns = [<span class="string">&#x27;Anxiety&#x27;</span>, <span class="string">&#x27;Depression&#x27;</span>, <span class="string">&#x27;Insomnia&#x27;</span>, <span class="string">&#x27;OCD&#x27;</span>, <span class="string">&#x27;Mental_Health_Score&#x27;</span>]</span><br><span class="line">genre_columns = [col <span class="keyword">for</span> col <span class="keyword">in</span> df_interest_encoded.columns <span class="keyword">if</span> col.startswith(<span class="string">&#x27;Fav genre_&#x27;</span>)]</span><br><span class="line"></span><br><span class="line">correlation_subset = correlation_matrix.loc[psych_columns, genre_columns]</span><br><span class="line"></span><br><span class="line">correlation_subset.columns = correlation_subset.columns.<span class="built_in">str</span>.replace(<span class="string">&#x27;Fav genre_&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Draw a heat map</span></span><br><span class="line">plt.figure(figsize=(<span class="number">16</span>, <span class="number">5</span>))</span><br><span class="line">sns.heatmap(correlation_subset, annot=<span class="literal">True</span>, cmap=<span class="string">&#x27;coolwarm&#x27;</span>, vmin=-<span class="number">0.3</span>, vmax=<span class="number">0.3</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Correlation between Music Taste and Self-reported Mental Health&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Music Genres&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Mental Health Conditions&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/INFO212-group18-code_files/INFO212-group18-code_16_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df_interest = df_improve[columns_of_interest]</span><br><span class="line">df_interest_encoded = pd.get_dummies(df_interest, columns=[<span class="string">&#x27;Fav genre&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Calculate correlation coefficient</span></span><br><span class="line">correlation_matrix = df_interest_encoded.corr()</span><br><span class="line"></span><br><span class="line">psych_columns = [<span class="string">&#x27;Anxiety&#x27;</span>, <span class="string">&#x27;Depression&#x27;</span>, <span class="string">&#x27;Insomnia&#x27;</span>, <span class="string">&#x27;OCD&#x27;</span>, <span class="string">&#x27;Mental_Health_Score&#x27;</span>]</span><br><span class="line">genre_columns = [col <span class="keyword">for</span> col <span class="keyword">in</span> df_interest_encoded.columns <span class="keyword">if</span> col.startswith(<span class="string">&#x27;Fav genre_&#x27;</span>)]</span><br><span class="line"></span><br><span class="line">correlation_subset = correlation_matrix.loc[psych_columns, genre_columns]</span><br><span class="line"></span><br><span class="line">correlation_subset.columns = correlation_subset.columns.<span class="built_in">str</span>.replace(<span class="string">&#x27;Fav genre_&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Draw a heat map</span></span><br><span class="line">plt.figure(figsize=(<span class="number">16</span>, <span class="number">5</span>))</span><br><span class="line">sns.heatmap(correlation_subset, annot=<span class="literal">True</span>, cmap=<span class="string">&#x27;coolwarm&#x27;</span>, vmin=-<span class="number">0.3</span>, vmax=<span class="number">0.3</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Correlation between Music Taste and Self-reported Mental Health&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Music Genres&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Mental Health Conditions&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/INFO212-group18-code_files/INFO212-group18-code_17_0.png" alt="png"></p><ol start="3"><li>Does frequency of listening to music affect mental health ratings?</li></ol><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Ensure that the &#x27;Hours per day&#x27; column is of integer type</span></span><br><span class="line">df_temp[<span class="string">&#x27;Hours per day&#x27;</span>] = df_temp[<span class="string">&#x27;Hours per day&#x27;</span>].astype(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Calculate the average mental health score and sample size for each group based on &#x27;Hours per day&#x27; minutes</span></span><br><span class="line">hours_health_score = df_temp[df_temp[<span class="string">&#x27;Hours per day&#x27;</span>] &lt; <span class="number">24</span>].groupby(<span class="string">&#x27;Hours per day&#x27;</span>).agg(</span><br><span class="line">    Average_Mental_Health_Score=(<span class="string">&#x27;Mental_Health_Score&#x27;</span>, <span class="string">&#x27;mean&#x27;</span>),</span><br><span class="line">    Sample_Size=(<span class="string">&#x27;Mental_Health_Score&#x27;</span>, <span class="string">&#x27;size&#x27;</span>)</span><br><span class="line">).reset_index()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a double Y-axis chart</span></span><br><span class="line">fig, ax1 = plt.subplots(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Draw a line graph of the average mental health score</span></span><br><span class="line">sns.lineplot(x=<span class="string">&#x27;Hours per day&#x27;</span>, y=<span class="string">&#x27;Average_Mental_Health_Score&#x27;</span>, data=hours_health_score, marker=<span class="string">&#x27;o&#x27;</span>, ax=ax1, color=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">ax1.set_xlabel(<span class="string">&#x27;Hours per day&#x27;</span>)</span><br><span class="line">ax1.set_ylabel(<span class="string">&#x27;Average Mental Health Score&#x27;</span>, color=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">ax1.tick_params(axis=<span class="string">&#x27;y&#x27;</span>, labelcolor=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a second Y-axis and draw a bar chart of the number of samples</span></span><br><span class="line">ax2 = ax1.twinx()</span><br><span class="line">sns.barplot(x=<span class="string">&#x27;Hours per day&#x27;</span>, y=<span class="string">&#x27;Sample_Size&#x27;</span>, data=hours_health_score, alpha=<span class="number">0.3</span>, ax=ax2, color=<span class="string">&#x27;g&#x27;</span>)</span><br><span class="line">ax2.set_ylabel(<span class="string">&#x27;Sample Size&#x27;</span>, color=<span class="string">&#x27;g&#x27;</span>)</span><br><span class="line">ax2.tick_params(axis=<span class="string">&#x27;y&#x27;</span>, labelcolor=<span class="string">&#x27;g&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set Title</span></span><br><span class="line">plt.title(<span class="string">&#x27;Average Mental Health Score by Hours of Music Listening per Day&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/INFO212-group18-code_files/INFO212-group18-code_19_0.png" alt="png"></p><ol start="5"><li>Is there a link between the BPM of music and mental health status?</li></ol><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Group according to BPM and calculate the average mental health score for each group</span></span><br><span class="line">bpm_health_score = df_temp[df_cleaned[<span class="string">&#x27;BPM&#x27;</span>] &lt;= <span class="number">300</span>].groupby(<span class="string">&#x27;BPM&#x27;</span>)[<span class="string">&#x27;Mental_Health_Score&#x27;</span>].mean().reset_index()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Draw a line chart</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">sns.lineplot(x=<span class="string">&#x27;BPM&#x27;</span>, y=<span class="string">&#x27;Mental_Health_Score&#x27;</span>, data=bpm_health_score, marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Average Mental Health Score by BPM&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;BPM&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Average Mental Health Score&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/INFO212-group18-code_files/INFO212-group18-code_21_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Group by &#x27;Primary streaming service&#x27; and calculate the average mental health score for each group</span></span><br><span class="line">streaming_health_score = df_temp.groupby(<span class="string">&#x27;Primary streaming service&#x27;</span>)[<span class="string">&#x27;Mental_Health_Score&#x27;</span>].mean().reset_index()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Draw a bar chart</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line">sns.barplot(x=<span class="string">&#x27;Primary streaming service&#x27;</span>, y=<span class="string">&#x27;Mental_Health_Score&#x27;</span>, data=streaming_health_score)</span><br><span class="line">plt.title(<span class="string">&#x27;Average Mental Health Score by Primary Streaming Service&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Primary Streaming Service&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Average Mental Health Score&#x27;</span>)</span><br><span class="line">plt.xticks(rotation=<span class="number">45</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/INFO212-group18-code_files/INFO212-group18-code_22_0.png" alt="png"></p><h1 id="Predict-model"><a href="#Predict-model" class="headerlink" title="Predict model"></a>Predict model</h1><ol start="4"><li>Do different genres of music have different effects on mental health depending on an<br>individual’s background (e.g., age, being an instrument player, etc.)</li></ol><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error, r2_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define independent and dependent variables</span></span><br><span class="line">X = df_temp[frequency_columns]</span><br><span class="line">y = df_temp[<span class="string">&#x27;Mental_Health_Score&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Split the data into training and testing sets</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Establish and train a linear regression model</span></span><br><span class="line">model = LinearRegression()</span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Forecast</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Evaluate model performance</span></span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line">r2 = r2_score(y_test, y_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Mean Squared Error: <span class="subst">&#123;mse&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;R^2 Score: <span class="subst">&#123;r2&#125;</span>&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>Mean Squared Error: 8.339662778833963R^2 Score: -0.03519094734086359</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neural_network <span class="keyword">import</span> MLPRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_absolute_error</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split, GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.neural_network <span class="keyword">import</span> MLPRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_absolute_error</span><br><span class="line"><span class="keyword">from</span> sklearn.exceptions <span class="keyword">import</span> ConvergenceWarning</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">additional_columns = [<span class="string">&#x27;Age&#x27;</span>, <span class="string">&#x27;Music Influenced&#x27;</span>]</span><br><span class="line">all_features = frequency_columns + additional_columns</span><br><span class="line">X = df_temp[all_features]</span><br><span class="line">y = df_temp[<span class="string">&#x27;Mental_Health_Score&#x27;</span>]</span><br><span class="line"><span class="comment"># Data preprocessing</span></span><br><span class="line">X = pd.get_dummies(X, columns=[<span class="string">&#x27;Music Influenced&#x27;</span>], drop_first=<span class="literal">True</span>)  <span class="comment"># Handling categorical variables</span></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">X_scaled = scaler.fit_transform(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Split the data into training and testing sets</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Defining a Random Forest Model</span></span><br><span class="line">model = RandomForestRegressor(random_state=<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define smaller grid search parameters</span></span><br><span class="line">param_grid = &#123;</span><br><span class="line">    <span class="string">&#x27;n_estimators&#x27;</span>: [<span class="number">100</span>, <span class="number">200</span>],</span><br><span class="line">    <span class="string">&#x27;max_depth&#x27;</span>: [<span class="literal">None</span>, <span class="number">10</span>, <span class="number">20</span>],</span><br><span class="line">    <span class="string">&#x27;min_samples_split&#x27;</span>: [<span class="number">2</span>, <span class="number">5</span>],</span><br><span class="line">    <span class="string">&#x27;min_samples_leaf&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">    <span class="string">&#x27;bootstrap&#x27;</span>: [<span class="literal">True</span>]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Using GridSearchCV for hyperparameter tuning</span></span><br><span class="line">grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=<span class="number">5</span>, scoring=<span class="string">&#x27;neg_mean_absolute_error&#x27;</span>, n_jobs=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training model</span></span><br><span class="line">grid_search.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Obtain optimal parameters</span></span><br><span class="line">best_params = grid_search.best_params_</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Best parameters found: <span class="subst">&#123;best_params&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Retrain model with optimal parameters</span></span><br><span class="line">best_model = grid_search.best_estimator_</span><br><span class="line"></span><br><span class="line"><span class="comment"># Evaluate model performance</span></span><br><span class="line">y_pred = best_model.predict(X_test)</span><br><span class="line">mae = mean_absolute_error(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Mean Absolute Error on Test Set: <span class="subst">&#123;mae&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Draw a comparison chart between predicted and actual values</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">plt.scatter(y_test, y_pred, alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.plot([-<span class="number">7</span>, <span class="number">7</span>], [-<span class="number">7</span>, <span class="number">7</span>], <span class="string">&#x27;--k&#x27;</span>)</span><br><span class="line">plt.xlim(-<span class="number">7</span>, <span class="number">7</span>)</span><br><span class="line">plt.ylim(-<span class="number">7</span>, <span class="number">7</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Actual Mental Health Score&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Predicted Mental Health Score&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Actual vs Predicted Mental Health Score&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><pre><code>Best parameters found: &#123;&#39;bootstrap&#39;: True, &#39;max_depth&#39;: 10, &#39;min_samples_leaf&#39;: 1, &#39;min_samples_split&#39;: 5, &#39;n_estimators&#39;: 100&#125;Mean Absolute Error on Test Set: 2.3499702701296608</code></pre><p><img src="/INFO212-group18-code_files/INFO212-group18-code_26_1.png" alt="png"></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Ignoring convergence warnings</span></span><br><span class="line">warnings.filterwarnings(<span class="string">&quot;ignore&quot;</span>, category=ConvergenceWarning)</span><br><span class="line"></span><br><span class="line">additional_columns = [<span class="string">&#x27;Age&#x27;</span>, <span class="string">&#x27;Music Influenced&#x27;</span>]</span><br><span class="line">all_features = frequency_columns + additional_columns</span><br><span class="line">X = df_temp[all_features]</span><br><span class="line">y = df_temp[<span class="string">&#x27;Mental_Health_Score&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Data preprocessing</span></span><br><span class="line">X = pd.get_dummies(X, columns=[<span class="string">&#x27;Music Influenced&#x27;</span>], drop_first=<span class="literal">True</span>)  <span class="comment"># Handling categorical variables</span></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">X_scaled = scaler.fit_transform(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Split the data into training and testing sets</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Defining neural network models</span></span><br><span class="line">model = MLPRegressor(max_iter=<span class="number">400</span>, early_stopping=<span class="literal">True</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set of defined values</span></span><br><span class="line">values = [<span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Generate all triples</span></span><br><span class="line">triplets = [(x, y, z) <span class="keyword">for</span> x <span class="keyword">in</span> values <span class="keyword">for</span> y <span class="keyword">in</span> values <span class="keyword">for</span> z <span class="keyword">in</span> values]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define grid search parameters</span></span><br><span class="line">param_grid = &#123;</span><br><span class="line">    <span class="string">&#x27;hidden_layer_sizes&#x27;</span>: triplets,</span><br><span class="line">    <span class="string">&#x27;activation&#x27;</span>: [<span class="string">&#x27;relu&#x27;</span>, <span class="string">&#x27;tanh&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;solver&#x27;</span>: [<span class="string">&#x27;adam&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;learning_rate&#x27;</span>: [<span class="string">&#x27;constant&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;alpha&#x27;</span>: [<span class="number">0.0001</span>, <span class="number">0.001</span>, <span class="number">0.01</span>, <span class="number">0.1</span>]  <span class="comment"># Different regularization parameter values</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Using GridSearchCV for hyperparameter tuning</span></span><br><span class="line">grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=<span class="number">5</span>, scoring=<span class="string">&#x27;neg_mean_absolute_error&#x27;</span>, n_jobs=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training model</span></span><br><span class="line">grid_search.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Obtain optimal parameters</span></span><br><span class="line">best_params = grid_search.best_params_</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Best parameters found: <span class="subst">&#123;best_params&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Retrain model with optimal parameters</span></span><br><span class="line">best_model = grid_search.best_estimator_</span><br><span class="line"></span><br><span class="line"><span class="comment"># Evaluate model performance</span></span><br><span class="line">y_pred = best_model.predict(X_test)</span><br><span class="line">mae = mean_absolute_error(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Mean Absolute Error on Test Set: <span class="subst">&#123;mae&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Draw a comparison chart between predicted and actual values</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">plt.scatter(y_test, y_pred, alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.plot([-<span class="number">7</span>, <span class="number">7</span>], [-<span class="number">7</span>, <span class="number">7</span>], <span class="string">&#x27;--k&#x27;</span>)</span><br><span class="line">plt.xlim(-<span class="number">7</span>, <span class="number">7</span>)</span><br><span class="line">plt.ylim(-<span class="number">7</span>, <span class="number">7</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Actual Mental Health Score&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Predicted Mental Health Score&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Actual vs Predicted Mental Health Score&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><pre><code>Best parameters found: &#123;&#39;activation&#39;: &#39;tanh&#39;, &#39;alpha&#39;: 0.1, &#39;hidden_layer_sizes&#39;: (30, 20, 20), &#39;learning_rate&#39;: &#39;constant&#39;, &#39;solver&#39;: &#39;adam&#39;&#125;Mean Absolute Error on Test Set: 2.103256690627413</code></pre><p><img src="/INFO212-group18-code_files/INFO212-group18-code_27_1.png" alt="png"></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_predict, learning_curve, cross_val_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error, r2_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># Calculate residuals</span></span><br><span class="line">y_train_pred = best_model.predict(X_train)</span><br><span class="line">y_test_pred = best_model.predict(X_test)</span><br><span class="line"></span><br><span class="line">train_residuals = y_train - y_train_pred</span><br><span class="line">test_residuals = y_test - y_test_pred</span><br><span class="line"></span><br><span class="line"><span class="comment"># Draw a scatter plot of predicted and actual values</span></span><br><span class="line">plt.figure(figsize=(<span class="number">14</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.scatter(y_train, y_train_pred, alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.plot([<span class="built_in">min</span>(y_train), <span class="built_in">max</span>(y_train)], [<span class="built_in">min</span>(y_train), <span class="built_in">max</span>(y_train)], <span class="string">&#x27;--k&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Actual Mental Health Score (Train)&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Predicted Mental Health Score (Train)&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Actual vs Predicted (Train)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.scatter(y_test, y_test_pred, alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.plot([<span class="built_in">min</span>(y_test), <span class="built_in">max</span>(y_test)], [<span class="built_in">min</span>(y_test), <span class="built_in">max</span>(y_test)], <span class="string">&#x27;--k&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Actual Mental Health Score (Test)&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Predicted Mental Health Score (Test)&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Actual vs Predicted (Test)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Draw residual distribution map</span></span><br><span class="line">plt.figure(figsize=(<span class="number">14</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.hist(train_residuals, bins=<span class="number">20</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Residuals&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Frequency&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Residuals Distribution (Train)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.hist(test_residuals, bins=<span class="number">20</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Residuals&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Frequency&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Residuals Distribution (Test)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Calculate cross validation score</span></span><br><span class="line">cv_scores = cross_val_score(best_model, X_scaled, y, cv=<span class="number">5</span>, scoring=<span class="string">&#x27;neg_mean_absolute_error&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Cross-validated MAE: <span class="subst">&#123;-cv_scores.mean()&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Draw a learning curve</span></span><br><span class="line">train_sizes, train_scores, test_scores = learning_curve(best_model, X_scaled, y, cv=<span class="number">5</span>, scoring=<span class="string">&#x27;neg_mean_absolute_error&#x27;</span>, train_sizes=np.linspace(<span class="number">0.1</span>, <span class="number">1.0</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">train_scores_mean = -np.mean(train_scores, axis=<span class="number">1</span>)</span><br><span class="line">test_scores_mean = -np.mean(test_scores, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">plt.plot(train_sizes, train_scores_mean, <span class="string">&#x27;o-&#x27;</span>, color=<span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;Training score&#x27;</span>)</span><br><span class="line">plt.plot(train_sizes, test_scores_mean, <span class="string">&#x27;o-&#x27;</span>, color=<span class="string">&#x27;g&#x27;</span>, label=<span class="string">&#x27;Cross-validation score&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Training Size&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Mean Absolute Error&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Learning Curve&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;best&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Evaluate model performance</span></span><br><span class="line">mse_train = mean_squared_error(y_train, y_train_pred)</span><br><span class="line">mse_test = mean_squared_error(y_test, y_test_pred)</span><br><span class="line">r2_train = r2_score(y_train, y_train_pred)</span><br><span class="line">r2_test = r2_score(y_test, y_test_pred)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Train MSE: <span class="subst">&#123;mse_train&#125;</span>, Train R2: <span class="subst">&#123;r2_train&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Test MSE: <span class="subst">&#123;mse_test&#125;</span>, Test R2: <span class="subst">&#123;r2_test&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="/INFO212-group18-code_files/INFO212-group18-code_28_0.png" alt="png"></p><p><img src="/INFO212-group18-code_files/INFO212-group18-code_28_1.png" alt="png"></p><pre><code>Cross-validated MAE: 2.323231447137279</code></pre><p><img src="/INFO212-group18-code_files/INFO212-group18-code_28_3.png" alt="png"></p><pre><code>Train MSE: 6.082415683585268, Train R2: 0.2410645098695644Test MSE: 7.30692075768475, Test R2: -0.005665782715258638</code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>记录一次失败的数学建模</title>
      <link href="/2024/07/17/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E5%A4%B1%E8%B4%A5%E7%9A%84%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"/>
      <url>/2024/07/17/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E5%A4%B1%E8%B4%A5%E7%9A%84%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/</url>
      
        <content type="html"><![CDATA[<p>基于机器学习的颅内感染数据分析研究</p><p><strong>摘要：</strong>本研究运用机器学习和数据分析技术，对颅内感染进行了深入研究。通过数据预处理、特征提取和模型训练等步骤，成功构建了预测颅内感染的机器学习模型。我们采用随机森林算法，并结合过采样技术解决类别不平衡问题，有效提高了模型的预测准确性。在模型验证阶段，各项性能指标均显示出模型具有良好的预测能力，可为医生提供辅助诊断。此外，数据分析还揭示了与颅内感染密切相关的因素，为临床治疗提供了新的线索。本研究不仅提升了颅内感染的诊断效率，也为未来医疗领域中机器学习和数据分析的广泛应用奠定了基础。</p><p><strong>关键词：</strong> 颅内感染；数据分析；随机森林；朴素贝叶斯</p><p>目录</p><p><a href="#%E7%A0%94%E7%A9%B6%E8%83%8C%E6%99%AF%E5%92%8C%E6%84%8F%E4%B9%89">一、 研究背景和意义</a></p><p><a href="#%E7%A0%94%E7%A9%B6%E8%83%8C%E6%99%AF">(一) 研究背景</a></p><p><a href="#%E7%A0%94%E7%A9%B6%E6%84%8F%E4%B9%89">(二) 研究意义</a></p><p><a href="#%E6%96%87%E7%8C%AE%E7%BB%BC%E8%BF%B0">二、 文献综述</a></p><p><a href="#%E6%95%B0%E6%8D%AE%E4%BB%8B%E7%BB%8D%E5%92%8C%E9%A2%84%E5%A4%84%E7%90%86">三、 数据介绍和预处理</a></p><p><a href="#%E9%A2%85%E5%86%85%E6%84%9F%E6%9F%93%E5%BD%B1%E5%93%8D%E5%9B%A0%E7%B4%A0%E5%88%86%E6%9E%90">四、 颅内感染影响因素分析</a></p><p><a href="#%E9%A2%85%E5%86%85%E6%84%9F%E6%9F%93%E7%9B%B8%E5%85%B3%E7%97%85%E7%97%87%E5%88%86%E6%9E%90">(一) 颅内感染相关病症分析</a></p><p><a href="#%E9%BA%BB%E9%86%89%E6%A8%A1%E5%BC%8F%E4%B8%8E%E9%A2%85%E5%86%85%E6%84%9F%E6%9F%93%E5%85%B3%E8%81%94%E6%80%A7%E5%88%86%E6%9E%90">(二) 麻醉模式与颅内感染关联性分析</a></p><p><a href="#%E9%A2%85%E5%86%85%E6%84%9F%E6%9F%93%E4%B8%8E%E5%B9%B4%E9%BE%84%E5%85%B3%E7%B3%BB%E5%88%86%E6%9E%90">(三) 颅内感染与年龄关系分析</a></p><p><a href="#%E9%A2%85%E5%86%85%E6%84%9F%E6%9F%93%E5%92%8C%E6%80%A7%E5%88%AB%E5%85%B3%E7%B3%BB%E5%88%86%E6%9E%90">(四) 颅内感染和性别关系分析</a></p><p><a href="#%E9%A2%85%E5%86%85%E6%84%9F%E6%9F%93%E4%B8%8E%E6%89%8B%E6%9C%AF%E7%B1%BB%E5%9E%8B%E7%9B%B8%E5%85%B3%E6%80%A7%E5%88%86%E6%9E%90">(五) 颅内感染与手术类型相关性分析</a></p><p><a href="#%E9%A2%85%E5%86%85%E6%84%9F%E6%9F%93%E4%B8%8E%E4%BD%8F%E9%99%A2%E5%A4%A9%E6%95%B0%E5%85%B3%E8%81%94%E6%80%A7%E5%88%86%E6%9E%90">(六) 颅内感染与住院天数关联性分析</a></p><p><a href="#%E9%A2%85%E5%86%85%E6%84%9F%E6%9F%93%E9%A3%8E%E9%99%A9%E6%A8%A1%E5%9E%8B%E5%BB%BA%E7%AB%8B">五、 颅内感染风险模型建立</a></p><p><a href="#%E7%89%B9%E5%BE%81%E9%87%8D%E8%A6%81%E6%80%A7%E5%88%86%E6%9E%90">(一) 特征重要性分析</a></p><p><a href="#%E5%9F%BA%E4%BA%8E%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%9E%84%E5%BB%BA%E9%A3%8E%E9%99%A9%E6%A8%A1%E5%9E%8B">(二) 基于朴素贝叶斯构建风险模型</a></p><p><a href="#%E5%9F%BA%E4%BA%8E%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E6%9E%84%E5%BB%BA%E9%A3%8E%E9%99%A9%E6%A8%A1%E5%9E%8B">(三) 基于随机森林构建风险模型</a></p><p><a href="#%E6%80%BB%E7%BB%93">六、 总结</a></p><p><a href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE">参考文献</a></p><h1 id="研究背景和意义"><a href="#研究背景和意义" class="headerlink" title="研究背景和意义"></a>研究背景和意义</h1><h2 id="研究背景"><a href="#研究背景" class="headerlink" title="研究背景"></a>研究背景</h2><p>在当今医疗科技迅猛发展的时代，颅内感染作为神经外科领域的一个重要议题，一直受到广泛的关注和研究。颅内感染不仅给患者带来极大的痛苦，还可能引发严重的并发症，甚至危及生命。因此，对于颅内感染的预防、诊断和治疗，一直是医学界研究的重点。近年来，随着机器学习和数据分析技术的不断进步，其在医疗领域的应用也日益广泛，为颅内感染的研究提供了新的思路和方法。</p><p>传统的颅内感染研究方法主要依赖于医生的临床经验和患者的临床表现，然而这种方法往往存在一定的主观性和局限性。首先，医生的临床经验虽然丰富，但受到个人知识和经验的影响，可能存在判断偏差。其次，患者的临床表现也可能受到多种因素的影响，如个体差异、病情严重程度等，导致诊断结果的不准确。因此，如何更准确地预测和诊断颅内感染，一直是医学界亟待解决的问题。</p><p>随着机器学习和数据分析技术的不断发展，其在医疗领域的应用也日益广泛。通过收集和分析大量的医疗数据，机器学习算法能够发现隐藏在数据中的规律和模式，为疾病的预测和诊断提供有力的支持。在颅内感染的研究中，机器学习和数据分析技术同样具有巨大的潜力。首先，通过收集和分析患者的医疗数据，如病史、症状、体征、影像学检查结果等，机器学习算法可以构建出预测颅内感染的模型。这些模型可以根据患者的个体特征和病情情况，预测患者发生颅内感染的风险和可能性，为医生提供更为准确的诊断依据。</p><p>其次，机器学习算法还可以对颅内感染的病因和发病机制进行深入的研究。通过对大量数据的分析，算法可以发现与颅内感染相关的因素和规律，为疾病的预防和治疗提供新的思路和方法。例如，通过分析手术室环境、医务人员操作等因素与颅内感染发生率之间的关系，可以制定出更为有效的预防策略。</p><p>此外，机器学习算法还可以应用于颅内感染的治疗方案优化。通过对患者的基因组学、影像学和临床数据等多个方面的信息进行分析和学习，算法可以为患者制定个性化的治疗方案，提高治疗效果和患者的生存率。综上所述，基于机器学习和数据分析的颅内感染研究具有重要的背景和意义。通过应用这些先进的技术和方法，我们可以更准确地预测和诊断颅内感染，为患者的健康保驾护航。</p><h2 id="研究意义"><a href="#研究意义" class="headerlink" title="研究意义"></a>研究意义</h2><p>颅内感染的影响因素多样，包括患者的年龄、性别、基础疾病（如免疫缺陷、糖尿病等）[1]、以前的医疗手术史、暴露于某些环境或地域因素，以及病原体的毒力和耐药性等。这些因素的复杂交互作用使得颅内感染的诊断和治疗成为一项挑战。分析这些影响因素可以帮助医生更好地理解疾病的发病机制，从而制定更有效的预防和治疗策略。</p><p>机器学习预测颅内感染的研究具有多方面的意义。通过训练包含大量患者数据的机器学习方法，可以构建出能够识别颅内感染风险的模型。这种模型能够综合考虑多种影响因素，并通过算法优化，提高预测的准确性。对于临床医生而言，这样的工具可以辅助他们在疾病早期阶段做出更准确的诊断，及时采取治疗措施，从而改善患者的预后。</p><p>利用机器学习进行颅内感染预测还能带来个性化医疗的优势。每个患者的情况都是独一无二的，机器学习模型可以根据个体的具体情况进行风险评估，为每位患者提供量身定做的监测和治疗方案。此外，机器学习模型还可以实时更新，随着新的数据和研究结果的出现而不断优化，确保预测工具始终基于最新的医学知识。在公共卫生层面，机器学习预测颅内感染的模型能够帮助卫生决策者了解哪些人群更易感染，以及在特定环境和条件下感染的风险。这对于制定针对性的预防措施、优化资源分配、减少医疗成本以及控制疾病传播都极为重要。</p><p>然而，要实现机器学习在预测颅内感染中的潜力，还需要克服一些挑战。数据的质量、多样性和可访问性是建立精确模型的关键。同时，必须保证模型的透明度和解释能力，以便医生和患者理解模型提供的预测和建议。</p><h1 id="文献综述"><a href="#文献综述" class="headerlink" title="文献综述"></a>文献综述</h1><p>颅内感染是一种涉及大脑和脊髓的严重疾病，可能由多种不同的病原体引起，包括细菌、病毒、真菌和寄生虫。这类感染可能导致一系列严重的神经系统并发症，甚至危及生命。因此，了解颅内感染的影响因素并采用机器学习技术预测感染的风险具有极其重要的临床和公共卫生意义。</p><p>在现有文献中，对颅内感染影响因素的分析已经揭示了多种与感染风险相关的因素。这些因素包括但不限于：患者的年龄、性别、基础疾病（如免疫缺陷、糖尿病等）[2]、以前的医疗手术史、暴露于某些环境或地域因素，以及病原体的毒力和耐药性等[3]。例如，一些研究表明，老年人和免疫系统受损的患者更容易发生细菌性脑膜炎[4]。同时，医院获得性感染，特别是在进行神经外科手术后，也是颅内感染的一个重要风险因素[5]。</p><p>近年来，机器学习技术在医学诊断和预测中的应用逐渐增多。在颅内感染的预测方面，研究者已经开始探索利用机器学习模型来预测感染的风险[6]。这些模型通常基于大量的患者数据，包括临床特征、实验室检查结果、影像学资料等，以训练算法识别潜在的感染风险[7, 8]。例如，一项研究使用逻辑回归和随机森林算法分析了细菌性脑膜炎的风险因素，并建立了预测模型。该模型展示了较高的敏感性和特异性，表明机器学习可以有效地用于颅内感染的预测[9]。机器学习预测颅内感染的研究不仅具有临床意义，也对公共卫生决策有重要影响。通过准确预测颅内感染的风险，可以帮助医生及时采取预防措施，减少感染发生率，同时优化医疗资源的分配[10]。此外，机器学习模型还可以帮助研究者更好地理解颅内感染的发病机制，为新的治疗方法的开发提供线索。</p><p>然而，文献也指出了机器学习在颅内感染预测中的一些挑战。数据的质量、多样性和可访问性是建立精确模型的关键[11]。同时，必须保证模型的透明度和解释能力，以便医生和患者理解模型提供的预测和建议[12]。此外，模型的泛化能力也是一个重要的考虑因素，需要通过独立数据集的验证来确保模型的稳定性和可靠性[13]。</p><p>综上所述，颅内感染影响因素的分析和机器学习预测研究是一个新兴且充满潜力的领域。尽管存在挑战，但现有文献表明，机器学习技术有望为颅内感染的预测和管理提供有力的工具，从而改善患者的治疗结果和生活质量。随着技术的不断进步和数据的积累，机器学习在颅内感染预测和治疗中的应用将变得越来越广泛，对提高人口健康水平和医疗质量产生深远影响。</p><h1 id="数据介绍和预处理"><a href="#数据介绍和预处理" class="headerlink" title="数据介绍和预处理"></a>数据介绍和预处理</h1><p><img src="/image/media/4c82bb747f91eecf5f555a7193244031.png"></p><p>本次所采用的数据如上图所示，包含8372个样本和35个变量，其中大部分是文本型变量，例如诊断结果，手术名称和麻醉名称等。从上图中可以看到，样本中存在不少的缺失值，在数据分析中，当存在缺失值时，如果处理不当，可能会导致模型产生偏差，因为大多数算法会简单地忽略含有缺失值的记录，这可能会造成重要的信息丢失，特别是当缺失值不是随机出现的时候。此外，缺失数据还可能引入噪声，影响模型的准确性和解释性。在医学研究中，病人的某些检查指标缺失可能与其疾病状态密切相关，若忽略了这一点，就可能得出错误的结论。因此，首先对缺失值进行统计，结果如下：</p><p><img src="/image/media/ce3877f6b98d50bca38c95dff2d35465.png" alt="图表, 条形图, 直方图 描述已自动生成"></p><p>图中柱状图不完整的部分即缺失值存在的地方，可以看到缺失值主要存在诊断和手术麻醉这几个变量中，结合实际情况这主要是因为大部分病人没有涉及10个诊断或者多项手术，因此这里先对缺失进行填充为无，后续再进行合并处理。</p><p><img src="/image/media/e46b334f129f2aadd8aeae5e44f93060.png"></p><p>缺失值处理后对其再次进行可视化分析，可以看到所有变量下的样本都达到了8372个，不存在缺失值，可以进行后续分析。</p><p><img src="/image/media/c658e6961a53b2e2d9c19a8b63b64594.png" alt="图表, 条形图 描述已自动生成"></p><p>由于是否颅内感染随机分布在十个诊断中的其中一个，因此这里先对齐进行合并，在综合判断该样本中是否存在有关颅内感染的描述，如果有的话标记为颅内感染，没有的话标记为非颅内感染，最后进行统计分析，结果如上图所示，可以看到样本中非颅内感染的数量更多，达到了5000个样本，颅内感染有关的达到了3000个。</p><h1 id="颅内感染影响因素分析"><a href="#颅内感染影响因素分析" class="headerlink" title="颅内感染影响因素分析"></a>颅内感染影响因素分析</h1><h2 id="颅内感染相关病症分析"><a href="#颅内感染相关病症分析" class="headerlink" title="颅内感染相关病症分析"></a>颅内感染相关病症分析</h2><p>首先，本文认为颅内感染的出现可以与其他症状有关联性，即有些症状会增加颅内感染的可能性，或者颅内感染会很大程度导致这种症状的发现，其次有些症状可能会一致颅内感染的发生，基于这个假设，再结合数据中都是文本类型的数据，这里采用词云图进行分析。</p><p>首先是非颅内感染数据对应的词云图：</p><p><img src="/image/media/a464e935aa21628ff4a2b679fc6d5d86.png" alt="图片包含 文本 描述已自动生成"></p><p>词云图是一种视觉化技术，用于以直观的方式显示文本数据中单词的频率。在词云中，单词的大小通常与它在文本中的出现频率成正比，即出现次数越多的单词，在图中的显示就越大。这种表示方式可以快速地传达出文本的关键信息，便于读者一眼看出重要内容。词云图的制作过程一般包括以下几个步骤：首先，需要对文本进行预处理，包括标准化（如转换为小写）、去除停用词（如“和”、“是”等常见但信息量小的词）、词干提取等。接下来，统计每个单词的出现频率。然后，根据频率和其他可选因素生成视觉化的词云图。</p><p>在非颅内感染的样本中，高频症状分别是出血、高血压、肺部、脑水肿和蛛网膜等词汇，接着对颅内感染的样本进行分析，结果如下：</p><p><img src="/image/media/f48e7db2d06c7ce07fb70f209e2173a1.png"></p><p>在颅内感染的样本中，脑积水、蛛网膜、出血同样是高频词，但是高血压肺部、脑水肿等词的频率降低，此外，创伤性、血症脑室等症状增加，说明这些和颅内感染的关联性更强。</p><h2 id="麻醉模式与颅内感染关联性分析"><a href="#麻醉模式与颅内感染关联性分析" class="headerlink" title="麻醉模式与颅内感染关联性分析"></a>麻醉模式与颅内感染关联性分析</h2><p><img src="/image/media/fde87fba9bb2eab5fbc733e14c53b97a.png" alt="图表, 条形图 描述已自动生成"></p><p>对颅内感染和非颅内感染对应的麻醉模型分别进行类别与数量统计，在一张图中用条形图进行可视化展示，首先，二者在气管插管全麻和局部浸润麻醉方面没有明显差异，但是在支气管插管全麻方面，颅内感染的情况明显高于非颅内感染。此外，喉罩全麻对应的结果其恰相反，颅内感染中几乎没有喉罩全麻的样本。</p><h2 id="颅内感染与年龄关系分析"><a href="#颅内感染与年龄关系分析" class="headerlink" title="颅内感染与年龄关系分析"></a>颅内感染与年龄关系分析</h2><p>这里使用直方图对年龄的分布情况进行分析，直方图通过一系列高度不等的纵向条纹或线段来表示数据分布的情况，直方图能够显示各组频数或数量分布的情况，易于展示各组之间的差别。</p><p>非颅内感染结果：</p><p><img src="/image/media/2857ac5620adf5d86e679b5d677ba870.png"></p><p>颅内感染结果：</p><p><img src="/image/media/0174520b2e2bf48d7701250ca1cb84c2.png" alt="图表, 直方图 描述已自动生成"></p><p>从可视化的结果来看，非颅内感染的群体年龄分布更广，在20-80这个区间内都有较多的分布，而非颅内感染主要集中在50-70这个区间段，从核密度曲线的走势变化来看，两种样本的情况基本相同，不存在显著差异。</p><h2 id="颅内感染和性别关系分析"><a href="#颅内感染和性别关系分析" class="headerlink" title="颅内感染和性别关系分析"></a>颅内感染和性别关系分析</h2><p><img src="/image/media/d314157544dc240727ee2cc9284fab25.png" alt="图表, 条形图 描述已自动生成"></p><p>颅内感染样本中，女性群体的占比略微高于非颅内感染的群体，但是由于样本的数量不够大，因此会有比较多的随机误差影响，这里认为是否颅内感染和性别之间不存在显著差异。</p><h2 id="颅内感染与手术类型相关性分析"><a href="#颅内感染与手术类型相关性分析" class="headerlink" title="颅内感染与手术类型相关性分析"></a>颅内感染与手术类型相关性分析</h2><p><img src="/image/media/feb5a0794d55f9e9b38479347929aa13.png" alt="图表, 条形图 描述已自动生成"></p><p>在每一个手术类型下，都有不同程度的颅内感染情况的发生，但是有四种类型的手术，发生颅内感染的概率尤其大 ，分别是’脑内血肿清除术’、颅内血肿清除术’、’脑室钻孔引流术’和’内镜下三叉神经微血管减压术’，这类手术直接与颅内有关。</p><h2 id="颅内感染与住院天数关联性分析"><a href="#颅内感染与住院天数关联性分析" class="headerlink" title="颅内感染与住院天数关联性分析"></a>颅内感染与住院天数关联性分析</h2><p><img src="/image/media/0ddc658610c77645ba4c7cf03773ff70.png" alt="图表 描述已自动生成"></p><p>使用groupby函数对是否颅内感染进行分类统计，然后计算住院天数的均值，最后使用环形饼图进行展示，从结果来看，颅内感染的住院天数约为98天，非颅内感染的住院天数约为30天，占比只有百分之二十三点四，二者存在显著差异。</p><h1 id="颅内感染风险模型建立"><a href="#颅内感染风险模型建立" class="headerlink" title="颅内感染风险模型建立"></a>颅内感染风险模型建立</h1><h2 id="特征重要性分析"><a href="#特征重要性分析" class="headerlink" title="特征重要性分析"></a>特征重要性分析</h2><p>随机森林是一种集成学习方法，它通过建立多棵决策树并让它们进行投票来决定最终的分类或回归结果。而随机森林的特征重要性评估，是这一算法中一个极为关键的部分，它不仅揭示了模型在做出预测时各个特征的影响程度，还为我们优化模型、理解数据提供了有力的支持。</p><p>在随机森林中，特征重要性通常通过两种方式来计算：一是基于基尼不纯度的减少量，二是基于袋外数据）的错误率变化。当使用基尼不纯度时，随机森林会衡量在每个特征节点分裂前后数据的不纯度变化，变化越大，则表明该特征对于减少数据不纯度、提高模型准确性贡献越大，因此该特征的重要性就越高。而在基于袋外数据的特征重要性评估中，随机森林利用未被用于训练某棵树的数据（即袋外数据）来评估该树对于该部分数据的预测性能，随后通过随机打乱某个特征的值来观察预测性能的变化。如果打乱某个特征后预测性能显著下降，则表明该特征对于模型预测至关重要。</p><p>进行特征重要性分析可以帮助我们识别数据中的关键特征，这些特征对于模型的预测性能有着至关重要的影响。通过了解这些关键特征，我们可以更加深入地理解数据的本质和模型的工作原理。其次，特征重要性分析有助于我们进行特征选择和降维。在实际应用中，数据的特征维度往往非常高，这可能导致模型训练困难、过拟合等问题。通过评估特征的重要性，我们可以选择性地保留重要特征，去除冗余或无关紧要的特征，从而简化模型，提高模型的泛化能力。此外，特征重要性分析还有助于我们进行特征工程。通过了解不同特征对模型的影响程度，我们可以有针对性地对数据进行预处理、变换或组合，以生成更具代表性的新特征，进一步提高模型的性能。</p><p><img src="/image/media/06b3a75c93276d98d938330be10c1977.png"></p><p>这里随机森林重要性分析的结果如上图所示，和前面探索性分析的结果一致，住院天数、诊断、手术类型等都对模型预测有了比较重要的贡献程度，而项目、定量结果、定型结果等对结果基本没有贡献，但是重要性大于0，而且这里特征数量不是特别多，因此对其进行保留。</p><h2 id="基于朴素贝叶斯构建风险模型"><a href="#基于朴素贝叶斯构建风险模型" class="headerlink" title="基于朴素贝叶斯构建风险模型"></a>基于朴素贝叶斯构建风险模型</h2><p>朴素贝叶斯模型是一种基于贝叶斯定理与特征条件独立假设的分类方法。其核心思想在于，对于给定的待分类项，通过计算此项出现的条件下各个类别出现的概率，哪个概率最大，就认为此待分类项属于哪个类别。这里的“朴素”一词来源于其对于特征之间关系的简化假设，即假设特征之间相互独立，互不影响。</p><p>在朴素贝叶斯模型中，待分类项通常由一个特征向量表示，这个特征向量包含了多个特征，每个特征都是待分类项的一个属性。例如，在文本分类中，待分类项可能是一篇文章，而特征则可能是文章中的单词。模型首先需要根据训练数据集学习出各个特征在各类别中出现的概率，即先验概率。当需要对新的待分类项进行分类时，朴素贝叶斯模型会先计算该待分类项在各个类别下出现的概率，这个概率的计算基于贝叶斯定理和特征条件独立假设。具体来说，模型会先计算待分类项中每个特征在各个类别下出现的概率，然后将这些概率相乘（由于假设特征之间相互独立），得到待分类项在各个类别下出现的联合概率。最后，模型会选择联合概率最大的类别作为待分类项的预测类别。</p><p>朴素贝叶斯模型的构建流程如下：首先通过data.drop([‘是否颅内感染’], axis&#x3D;1)移除了数据集中的因变量（即是否颅内感染这一列），保留了所有的自变量（特征），然后将因变量赋值给y。为了处理数据集中可能存在的类别不平衡问题（即颅内感染和非颅内感染样本数量不等），代码使用了SMOTE过采样技术，从少数类（颅内感染）中生成合成样本，使得两类样本数量相近。在数据预处理完成后，代码使用train_test_split函数将数据集划分为训练集和验证集，其中验证集占数据总量的30%。然后，定义了一个基于高斯分布的朴素贝叶斯分类器GaussianNB，并用训练集数据对其进行训练。训练完成后，代码使用验证集数据对模型进行了预测，并计算了接收者操作特征曲线（ROC曲线）下的面积（AUC值），这是评估二分类模型性能的一个重要指标。AUC值越接近1，说明模型的性能越好。</p><p><img src="/image/media/20a47e4bac9904a25befb5a727d4e635.png" alt="图表, 折线图 描述已自动生成"></p><p>从roc曲线来看，朴素贝叶斯模型在一定程度上对是否颅内感染有预测能力，但是效果比较一般，在0.6以下的这个区域内，很少进行有效预测。</p><p>此外，还计算了模型的准确率、精确率、召回率和F1值，这些指标从不同角度评估了模型的性能。准确率衡量了模型预测正确的比例；精确率衡量了模型预测为正样本的实例中真正为正样本的比例；召回率衡量了所有真正为正样本的实例中被模型预测出来的比例；F1值是精确率和召回率的调和平均数，用于综合评估模型的性能。朴素贝叶斯的结果为：准确率0.7314396384764364，精确率0.6812182741116751，召回率0.8680465717981889，f值0.7633674630261661。为了进一步探索模型的性能，这里使用混淆矩阵进行分析：</p><p><img src="/image/media/88f5b6a0cef25acaba16ffd2ca52a908.png"></p><p>从图中来看，在朴素贝叶斯模型中，0标签预测正确有920个，预测错误有630个，1标签预测正确有1300个，预测错误有200个。说明该模型对1标签的预测能力更强，即预测非颅内感染的能力更好，不过这也跟数据样本不平衡有关。</p><h2 id="基于随机森林构建风险模型"><a href="#基于随机森林构建风险模型" class="headerlink" title="基于随机森林构建风险模型"></a>基于随机森林构建风险模型</h2><p>随机森林是一种强大的集成学习方法，它通过构建多个决策树并集成它们的预测结果来改进分类和回归任务的性能。随机森林模型的核心思想是利用“集思广益”的策略，通过随机选择特征和样本子集来训练多棵决策树，然后将这些决策树的预测结果进行投票或平均，以得出最终的预测结果。</p><p>在随机森林的构建过程中，每个决策树都是基于原始数据的一个随机子集进行训练的，这有助于减少过拟合现象，因为每个决策树都不会完全依赖于整个数据集。此外，每个决策树在分裂节点时，也会随机选择一部分特征作为候选分裂特征，而不是使用所有特征，这进一步增加了模型的多样性，提高了模型的泛化能力。</p><p>随机森林模型的主要优点包括高准确性：由于集成了多棵决策树的预测结果，随机森林通常能够获得比单一决策树更高的预测准确性。抗过拟合：通过随机选择特征和样本子集进行训练，随机森林模型能够有效地减少过拟合现象。特征重要性评估：随机森林模型能够计算每个特征对模型预测结果的重要性，这对于特征选择和解释模型预测结果非常有帮助。易于实现和调参：随机森林模型实现简单，参数较少，易于理解和调参。</p><p>这里随机森林模型的预测过程和贝叶斯基本相同，不再赘述，直接进行结果分析。</p><p><img src="/image/media/5218b947ef756e209b3108bf0871eccb.png" alt="图表, 折线图 描述已自动生成"></p><p><img src="/image/media/c373a70ba631db9fe678a0352d990eb7.png"></p><p>在随机森林模型中，auc值0.8456829896907216，准确率0.8453841187863137，精确率0.7634567901234568，召回率1.0，f值0.8658639036684402。再从roc曲线来看，整体走势更加平滑，能够有效对是否颅内感染进行预测，此外，0标签预测正确有1100个，预测错误有480个，1标签预测正确有1500个，预测错误有0个。虽然一样说明该模型对1标签的预测能力更强，即预测非颅内感染的能力更好，但是整体都实现了提升。</p><p>最后选择表现更加优秀的随机森林模型进行风险概率值的预测输出，结果如下：</p><p><img src="/image/media/78f2456e56da731acad11e8cde23aab0.png"></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>在医疗领域，颅内感染一直是一个严峻的挑战，它不仅对患者的生命安全构成威胁，同时也给医疗系统带来了沉重的负担。近年来，随着机器学习和数据分析技术的快速发展，我们得以运用这些先进工具对颅内感染进行更深入的研究，以期提高诊断的准确性和治疗的效率。</p><p>本研究采用了多种机器学习和数据分析技术，对大量医疗数据进行了挖掘和分析。首先，我们利用数据预处理技术，对原始数据进行了清洗、转换和标准化，确保数据的质量和一致性。接着，我们提取了与颅内感染相关的关键特征，如患者的年龄、性别、症状等，这些特征为后续的模型训练提供了基础。</p><p>在模型选择方面，我们尝试了多种分类算法，包括朴素贝叶斯、随机森林。通过对不同算法的比较和评估，我们发现随机森林模型在预测颅内感染方面表现出了较高的准确性。随机森林通过集成多棵决策树的预测结果，能够有效减少过拟合现象，提高模型的泛化能力。</p><p>为了进一步优化模型性能，我们采用了过采样技术来处理数据集中的类别不平衡问题。颅内感染作为少数类，其样本数量相对较少，这可能导致模型在训练过程中偏向于多数类。通过过采样技术，我们增加了少数类样本的数量，使得模型能够更好地学习少数类的特征，从而提高预测准确性。</p><p>在模型训练完成后，我们在验证集上进行了性能测试。通过计算准确率、精确率、召回率和F1值等指标，我们全面评估了模型的性能。结果显示，随机森林模型在颅内感染预测方面取得了令人满意的效果，能够为医生提供有力的诊断辅助工具。</p><p>除了模型预测外，我们还利用数据分析技术对颅内感染的相关因素进行了深入研究。通过对患者数据的统计分析，我们发现年龄、病史和某些特定症状与颅内感染的发生密切相关。这些发现为医生提供了更多的诊断线索和治疗依据。总的来说，本研究利用机器学习和数据分析技术对颅内感染进行了深入研究，取得了显著的成果。未来，我们将继续探索更多先进的算法和技术，以期在医疗领域发挥更大的作用，为患者提供更准确、更高效的诊断和治疗服务。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] 周霜, 张瑞敏, 付立平. 个体化预测神经外科患者术后颅内感染风险的列线图模型的建立 [J]. 护士进修杂志, 2020, 35(20): 1843-7.</p><p>[2] 葛风, 蒋云召, 陆华, et al. 重型颅脑外伤术后颅内感染患者高迁移率族蛋白B-1和炎症因子表达水平 [J]. 中华医院感染学杂志, 2019, 29(17): 2661-4.</p><p>[3] 张翡, 赵建凯, 杨利辉, et al. 个体化预测重症高血压脑出血患者行有创颅内压监测术后发生颅内感染的风险预测Nomgram模型的建立 [J]. 四川医学, 2021, 42(10): 985-90.</p><p>[4] 张国新, 隋明亮, 张劲松. 降钙素原对开颅术后颅内感染的早期诊断及预后预测价值 [J]. 广东医学, 2015, 36(20): 3152-6.</p><p>[5] 黄胜明, 邢泽刚. 脑脊液与血清降钙素原检测对术后颅内感染的预测价值探讨 [J]. 当代医学, 2019, 25(28): 159-61.</p><p>[6] 聂柳, 崔勇, 刘兴吉, et al. 开颅手术患者术后炎症因子水平变化预测颅内感染的临床价值 [J]. 中国老年学杂志, 2017, 37(08): 1963-5.</p><p>[7] 宋超强, 赵保钢, 孙智宏. 探讨引发颅脑损伤术后并发颅内感染的高危因素及预后预测研究 [J]. 中国临床医生杂志, 2023, 51(04): 465-8.</p><p>[8] 张丹梅, 袁丽, 朱琪. 开颅手术后颅内感染风险预测模型构建及效果评价 [J]. 中国感染控制杂志, 2022, 21(05): 439-46.</p><p>[9] 张丹霓. 经颅多普勒在颅内感染和脑出血初期颅高压的对比 [J]. 中国实用医药, 2016, 11(10): 55-6.</p><p>[10] HONG Z, XIAOLU T, YANQIU L, et al. Amide Proton Transfer-Weighted (APTw) Imaging of Intracranial Infection in Children: Initial Experience and Comparison with Gadolinium-Enhanced T1-Weighted Imaging [J]. BioMed research international, 2020, 2020: 6418343.</p><p>[11] LAN G, XIAOLIANG Y, HUIKANG Y, et al. Application value analysis of magnetic resonance imaging and computed tomography in the diagnosis of intracranial infection after craniocerebral surgery [J]. World journal of clinical cases, 2020, 8(23): 5894-901.</p><p>[12] PENGFEI F, YI Z, JUN Z, et al. Prediction of Intracranial Infection in Patients under External Ventricular Drainage and Neurological Intensive Care: A Multicenter Retrospective Cohort Study [J]. Journal of Clinical Medicine, 2022, 11(14): 3973-.</p><p>[13] YEONG-JIN K, KYUNG-SUB M, KEE K S, et al. The difference in diffusion-weighted imaging with apparent diffusion coefficient between spontaneous and postoperative intracranial infection [J]. British journal of neurosurgery, 2014, 28(6): 765-70.</p><h1 id=""><a href="#" class="headerlink" title=""></a></h1>]]></content>
      
      
      <categories>
          
          <category> 数学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 建模 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2024/07/13/hello-world/"/>
      <url>/2024/07/13/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
    </entry>
    
    
  
  
</search>
